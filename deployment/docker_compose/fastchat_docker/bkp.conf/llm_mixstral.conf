[supervisord]
nodaemon=true

[program:controller]
command=python3 -m fastchat.serve.controller --host '0.0.0.0'
stdout_logfile=/dev/stdout 
stdout_maxbytes=0 
stderr_logfile=/dev/stderr 
stderr_maxbytes=0 
autorestart=true 
startretries=100 
startsecs=60

[program:vllm_worker]
command=python3 -m fastchat.serve.vllm_worker --model-name 'Mixtral-8x7B-Instruct-v0.1' --model-path /app/models/mistralai/Mixtral-8x7B-Instruct-v0.1/models--mistralai--Mixtral-8x7B-Instruct-v0.1/snapshots/1e637f2d7cb0a9d6fb1922f305cb784995190a83 --host '0.0.0.0' --num-gpus 2 --dtype half
stdout_logfile=/dev/stdout 
stdout_maxbytes=0 
stderr_logfile=/dev/stderr 
stderr_maxbytes=0 
autorestart=true 
startretries=100 
startsecs=60

[program:openai_api_server]
command=python3 -m fastchat.serve.openai_api_server --host '0.0.0.0' --port 9199
stdout_logfile=/dev/stdout 
stdout_maxbytes=0 
stderr_logfile=/dev/stderr 
stderr_maxbytes=0 
autorestart=true 
startretries=100 
startsecs=60